{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPKSquPAeLJu"
   },
   "source": [
    "# **Problem** **1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lvh12srTeLJv"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCRPr5hTeLJz"
   },
   "outputs": [],
   "source": [
    "data = fetch_openml(data_id=40926) # get CIFAR-10 data from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "2tQ1s9YceLJ2",
    "outputId": "941f82ff-544a-4be1-e832-6906e6323041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 59.,  43.,  50., ..., 140.,  84.,  72.],\n",
      "       [154., 126., 105., ..., 139., 142., 144.],\n",
      "       [255., 253., 253., ...,  83.,  83.,  84.],\n",
      "       ...,\n",
      "       [ 20.,  19.,  15., ...,  50.,  53.,  47.],\n",
      "       [ 25.,  15.,  23., ...,  80.,  81.,  80.],\n",
      "       [ 73.,  98.,  99., ...,  94.,  58.,  26.]]), 'target': array(['6', '9', '9', ..., '5', '1', '7'], dtype=object), 'frame': None, 'feature_names': ['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19', 'a20', 'a21', 'a22', 'a23', 'a24', 'a25', 'a26', 'a27', 'a28', 'a29', 'a30', 'a31', 'a32', 'a33', 'a34', 'a35', 'a36', 'a37', 'a38', 'a39', 'a40', 'a41', 'a42', 'a43', 'a44', 'a45', 'a46', 'a47', 'a48', 'a49', 'a50', 'a51', 'a52', 'a53', 'a54', 'a55', 'a56', 'a57', 'a58', 'a59', 'a60', 'a61', 'a62', 'a63', 'a64', 'a65', 'a66', 'a67', 'a68', 'a69', 'a70', 'a71', 'a72', 'a73', 'a74', 'a75', 'a76', 'a77', 'a78', 'a79', 'a80', 'a81', 'a82', 'a83', 'a84', 'a85', 'a86', 'a87', 'a88', 'a89', 'a90', 'a91', 'a92', 'a93', 'a94', 'a95', 'a96', 'a97', 'a98', 'a99', 'a100', 'a101', 'a102', 'a103', 'a104', 'a105', 'a106', 'a107', 'a108', 'a109', 'a110', 'a111', 'a112', 'a113', 'a114', 'a115', 'a116', 'a117', 'a118', 'a119', 'a120', 'a121', 'a122', 'a123', 'a124', 'a125', 'a126', 'a127', 'a128', 'a129', 'a130', 'a131', 'a132', 'a133', 'a134', 'a135', 'a136', 'a137', 'a138', 'a139', 'a140', 'a141', 'a142', 'a143', 'a144', 'a145', 'a146', 'a147', 'a148', 'a149', 'a150', 'a151', 'a152', 'a153', 'a154', 'a155', 'a156', 'a157', 'a158', 'a159', 'a160', 'a161', 'a162', 'a163', 'a164', 'a165', 'a166', 'a167', 'a168', 'a169', 'a170', 'a171', 'a172', 'a173', 'a174', 'a175', 'a176', 'a177', 'a178', 'a179', 'a180', 'a181', 'a182', 'a183', 'a184', 'a185', 'a186', 'a187', 'a188', 'a189', 'a190', 'a191', 'a192', 'a193', 'a194', 'a195', 'a196', 'a197', 'a198', 'a199', 'a200', 'a201', 'a202', 'a203', 'a204', 'a205', 'a206', 'a207', 'a208', 'a209', 'a210', 'a211', 'a212', 'a213', 'a214', 'a215', 'a216', 'a217', 'a218', 'a219', 'a220', 'a221', 'a222', 'a223', 'a224', 'a225', 'a226', 'a227', 'a228', 'a229', 'a230', 'a231', 'a232', 'a233', 'a234', 'a235', 'a236', 'a237', 'a238', 'a239', 'a240', 'a241', 'a242', 'a243', 'a244', 'a245', 'a246', 'a247', 'a248', 'a249', 'a250', 'a251', 'a252', 'a253', 'a254', 'a255', 'a256', 'a257', 'a258', 'a259', 'a260', 'a261', 'a262', 'a263', 'a264', 'a265', 'a266', 'a267', 'a268', 'a269', 'a270', 'a271', 'a272', 'a273', 'a274', 'a275', 'a276', 'a277', 'a278', 'a279', 'a280', 'a281', 'a282', 'a283', 'a284', 'a285', 'a286', 'a287', 'a288', 'a289', 'a290', 'a291', 'a292', 'a293', 'a294', 'a295', 'a296', 'a297', 'a298', 'a299', 'a300', 'a301', 'a302', 'a303', 'a304', 'a305', 'a306', 'a307', 'a308', 'a309', 'a310', 'a311', 'a312', 'a313', 'a314', 'a315', 'a316', 'a317', 'a318', 'a319', 'a320', 'a321', 'a322', 'a323', 'a324', 'a325', 'a326', 'a327', 'a328', 'a329', 'a330', 'a331', 'a332', 'a333', 'a334', 'a335', 'a336', 'a337', 'a338', 'a339', 'a340', 'a341', 'a342', 'a343', 'a344', 'a345', 'a346', 'a347', 'a348', 'a349', 'a350', 'a351', 'a352', 'a353', 'a354', 'a355', 'a356', 'a357', 'a358', 'a359', 'a360', 'a361', 'a362', 'a363', 'a364', 'a365', 'a366', 'a367', 'a368', 'a369', 'a370', 'a371', 'a372', 'a373', 'a374', 'a375', 'a376', 'a377', 'a378', 'a379', 'a380', 'a381', 'a382', 'a383', 'a384', 'a385', 'a386', 'a387', 'a388', 'a389', 'a390', 'a391', 'a392', 'a393', 'a394', 'a395', 'a396', 'a397', 'a398', 'a399', 'a400', 'a401', 'a402', 'a403', 'a404', 'a405', 'a406', 'a407', 'a408', 'a409', 'a410', 'a411', 'a412', 'a413', 'a414', 'a415', 'a416', 'a417', 'a418', 'a419', 'a420', 'a421', 'a422', 'a423', 'a424', 'a425', 'a426', 'a427', 'a428', 'a429', 'a430', 'a431', 'a432', 'a433', 'a434', 'a435', 'a436', 'a437', 'a438', 'a439', 'a440', 'a441', 'a442', 'a443', 'a444', 'a445', 'a446', 'a447', 'a448', 'a449', 'a450', 'a451', 'a452', 'a453', 'a454', 'a455', 'a456', 'a457', 'a458', 'a459', 'a460', 'a461', 'a462', 'a463', 'a464', 'a465', 'a466', 'a467', 'a468', 'a469', 'a470', 'a471', 'a472', 'a473', 'a474', 'a475', 'a476', 'a477', 'a478', 'a479', 'a480', 'a481', 'a482', 'a483', 'a484', 'a485', 'a486', 'a487', 'a488', 'a489', 'a490', 'a491', 'a492', 'a493', 'a494', 'a495', 'a496', 'a497', 'a498', 'a499', 'a500', 'a501', 'a502', 'a503', 'a504', 'a505', 'a506', 'a507', 'a508', 'a509', 'a510', 'a511', 'a512', 'a513', 'a514', 'a515', 'a516', 'a517', 'a518', 'a519', 'a520', 'a521', 'a522', 'a523', 'a524', 'a525', 'a526', 'a527', 'a528', 'a529', 'a530', 'a531', 'a532', 'a533', 'a534', 'a535', 'a536', 'a537', 'a538', 'a539', 'a540', 'a541', 'a542', 'a543', 'a544', 'a545', 'a546', 'a547', 'a548', 'a549', 'a550', 'a551', 'a552', 'a553', 'a554', 'a555', 'a556', 'a557', 'a558', 'a559', 'a560', 'a561', 'a562', 'a563', 'a564', 'a565', 'a566', 'a567', 'a568', 'a569', 'a570', 'a571', 'a572', 'a573', 'a574', 'a575', 'a576', 'a577', 'a578', 'a579', 'a580', 'a581', 'a582', 'a583', 'a584', 'a585', 'a586', 'a587', 'a588', 'a589', 'a590', 'a591', 'a592', 'a593', 'a594', 'a595', 'a596', 'a597', 'a598', 'a599', 'a600', 'a601', 'a602', 'a603', 'a604', 'a605', 'a606', 'a607', 'a608', 'a609', 'a610', 'a611', 'a612', 'a613', 'a614', 'a615', 'a616', 'a617', 'a618', 'a619', 'a620', 'a621', 'a622', 'a623', 'a624', 'a625', 'a626', 'a627', 'a628', 'a629', 'a630', 'a631', 'a632', 'a633', 'a634', 'a635', 'a636', 'a637', 'a638', 'a639', 'a640', 'a641', 'a642', 'a643', 'a644', 'a645', 'a646', 'a647', 'a648', 'a649', 'a650', 'a651', 'a652', 'a653', 'a654', 'a655', 'a656', 'a657', 'a658', 'a659', 'a660', 'a661', 'a662', 'a663', 'a664', 'a665', 'a666', 'a667', 'a668', 'a669', 'a670', 'a671', 'a672', 'a673', 'a674', 'a675', 'a676', 'a677', 'a678', 'a679', 'a680', 'a681', 'a682', 'a683', 'a684', 'a685', 'a686', 'a687', 'a688', 'a689', 'a690', 'a691', 'a692', 'a693', 'a694', 'a695', 'a696', 'a697', 'a698', 'a699', 'a700', 'a701', 'a702', 'a703', 'a704', 'a705', 'a706', 'a707', 'a708', 'a709', 'a710', 'a711', 'a712', 'a713', 'a714', 'a715', 'a716', 'a717', 'a718', 'a719', 'a720', 'a721', 'a722', 'a723', 'a724', 'a725', 'a726', 'a727', 'a728', 'a729', 'a730', 'a731', 'a732', 'a733', 'a734', 'a735', 'a736', 'a737', 'a738', 'a739', 'a740', 'a741', 'a742', 'a743', 'a744', 'a745', 'a746', 'a747', 'a748', 'a749', 'a750', 'a751', 'a752', 'a753', 'a754', 'a755', 'a756', 'a757', 'a758', 'a759', 'a760', 'a761', 'a762', 'a763', 'a764', 'a765', 'a766', 'a767', 'a768', 'a769', 'a770', 'a771', 'a772', 'a773', 'a774', 'a775', 'a776', 'a777', 'a778', 'a779', 'a780', 'a781', 'a782', 'a783', 'a784', 'a785', 'a786', 'a787', 'a788', 'a789', 'a790', 'a791', 'a792', 'a793', 'a794', 'a795', 'a796', 'a797', 'a798', 'a799', 'a800', 'a801', 'a802', 'a803', 'a804', 'a805', 'a806', 'a807', 'a808', 'a809', 'a810', 'a811', 'a812', 'a813', 'a814', 'a815', 'a816', 'a817', 'a818', 'a819', 'a820', 'a821', 'a822', 'a823', 'a824', 'a825', 'a826', 'a827', 'a828', 'a829', 'a830', 'a831', 'a832', 'a833', 'a834', 'a835', 'a836', 'a837', 'a838', 'a839', 'a840', 'a841', 'a842', 'a843', 'a844', 'a845', 'a846', 'a847', 'a848', 'a849', 'a850', 'a851', 'a852', 'a853', 'a854', 'a855', 'a856', 'a857', 'a858', 'a859', 'a860', 'a861', 'a862', 'a863', 'a864', 'a865', 'a866', 'a867', 'a868', 'a869', 'a870', 'a871', 'a872', 'a873', 'a874', 'a875', 'a876', 'a877', 'a878', 'a879', 'a880', 'a881', 'a882', 'a883', 'a884', 'a885', 'a886', 'a887', 'a888', 'a889', 'a890', 'a891', 'a892', 'a893', 'a894', 'a895', 'a896', 'a897', 'a898', 'a899', 'a900', 'a901', 'a902', 'a903', 'a904', 'a905', 'a906', 'a907', 'a908', 'a909', 'a910', 'a911', 'a912', 'a913', 'a914', 'a915', 'a916', 'a917', 'a918', 'a919', 'a920', 'a921', 'a922', 'a923', 'a924', 'a925', 'a926', 'a927', 'a928', 'a929', 'a930', 'a931', 'a932', 'a933', 'a934', 'a935', 'a936', 'a937', 'a938', 'a939', 'a940', 'a941', 'a942', 'a943', 'a944', 'a945', 'a946', 'a947', 'a948', 'a949', 'a950', 'a951', 'a952', 'a953', 'a954', 'a955', 'a956', 'a957', 'a958', 'a959', 'a960', 'a961', 'a962', 'a963', 'a964', 'a965', 'a966', 'a967', 'a968', 'a969', 'a970', 'a971', 'a972', 'a973', 'a974', 'a975', 'a976', 'a977', 'a978', 'a979', 'a980', 'a981', 'a982', 'a983', 'a984', 'a985', 'a986', 'a987', 'a988', 'a989', 'a990', 'a991', 'a992', 'a993', 'a994', 'a995', 'a996', 'a997', 'a998', 'a999', 'a1000', 'a1001', 'a1002', 'a1003', 'a1004', 'a1005', 'a1006', 'a1007', 'a1008', 'a1009', 'a1010', 'a1011', 'a1012', 'a1013', 'a1014', 'a1015', 'a1016', 'a1017', 'a1018', 'a1019', 'a1020', 'a1021', 'a1022', 'a1023', 'a1024', 'a1025', 'a1026', 'a1027', 'a1028', 'a1029', 'a1030', 'a1031', 'a1032', 'a1033', 'a1034', 'a1035', 'a1036', 'a1037', 'a1038', 'a1039', 'a1040', 'a1041', 'a1042', 'a1043', 'a1044', 'a1045', 'a1046', 'a1047', 'a1048', 'a1049', 'a1050', 'a1051', 'a1052', 'a1053', 'a1054', 'a1055', 'a1056', 'a1057', 'a1058', 'a1059', 'a1060', 'a1061', 'a1062', 'a1063', 'a1064', 'a1065', 'a1066', 'a1067', 'a1068', 'a1069', 'a1070', 'a1071', 'a1072', 'a1073', 'a1074', 'a1075', 'a1076', 'a1077', 'a1078', 'a1079', 'a1080', 'a1081', 'a1082', 'a1083', 'a1084', 'a1085', 'a1086', 'a1087', 'a1088', 'a1089', 'a1090', 'a1091', 'a1092', 'a1093', 'a1094', 'a1095', 'a1096', 'a1097', 'a1098', 'a1099', 'a1100', 'a1101', 'a1102', 'a1103', 'a1104', 'a1105', 'a1106', 'a1107', 'a1108', 'a1109', 'a1110', 'a1111', 'a1112', 'a1113', 'a1114', 'a1115', 'a1116', 'a1117', 'a1118', 'a1119', 'a1120', 'a1121', 'a1122', 'a1123', 'a1124', 'a1125', 'a1126', 'a1127', 'a1128', 'a1129', 'a1130', 'a1131', 'a1132', 'a1133', 'a1134', 'a1135', 'a1136', 'a1137', 'a1138', 'a1139', 'a1140', 'a1141', 'a1142', 'a1143', 'a1144', 'a1145', 'a1146', 'a1147', 'a1148', 'a1149', 'a1150', 'a1151', 'a1152', 'a1153', 'a1154', 'a1155', 'a1156', 'a1157', 'a1158', 'a1159', 'a1160', 'a1161', 'a1162', 'a1163', 'a1164', 'a1165', 'a1166', 'a1167', 'a1168', 'a1169', 'a1170', 'a1171', 'a1172', 'a1173', 'a1174', 'a1175', 'a1176', 'a1177', 'a1178', 'a1179', 'a1180', 'a1181', 'a1182', 'a1183', 'a1184', 'a1185', 'a1186', 'a1187', 'a1188', 'a1189', 'a1190', 'a1191', 'a1192', 'a1193', 'a1194', 'a1195', 'a1196', 'a1197', 'a1198', 'a1199', 'a1200', 'a1201', 'a1202', 'a1203', 'a1204', 'a1205', 'a1206', 'a1207', 'a1208', 'a1209', 'a1210', 'a1211', 'a1212', 'a1213', 'a1214', 'a1215', 'a1216', 'a1217', 'a1218', 'a1219', 'a1220', 'a1221', 'a1222', 'a1223', 'a1224', 'a1225', 'a1226', 'a1227', 'a1228', 'a1229', 'a1230', 'a1231', 'a1232', 'a1233', 'a1234', 'a1235', 'a1236', 'a1237', 'a1238', 'a1239', 'a1240', 'a1241', 'a1242', 'a1243', 'a1244', 'a1245', 'a1246', 'a1247', 'a1248', 'a1249', 'a1250', 'a1251', 'a1252', 'a1253', 'a1254', 'a1255', 'a1256', 'a1257', 'a1258', 'a1259', 'a1260', 'a1261', 'a1262', 'a1263', 'a1264', 'a1265', 'a1266', 'a1267', 'a1268', 'a1269', 'a1270', 'a1271', 'a1272', 'a1273', 'a1274', 'a1275', 'a1276', 'a1277', 'a1278', 'a1279', 'a1280', 'a1281', 'a1282', 'a1283', 'a1284', 'a1285', 'a1286', 'a1287', 'a1288', 'a1289', 'a1290', 'a1291', 'a1292', 'a1293', 'a1294', 'a1295', 'a1296', 'a1297', 'a1298', 'a1299', 'a1300', 'a1301', 'a1302', 'a1303', 'a1304', 'a1305', 'a1306', 'a1307', 'a1308', 'a1309', 'a1310', 'a1311', 'a1312', 'a1313', 'a1314', 'a1315', 'a1316', 'a1317', 'a1318', 'a1319', 'a1320', 'a1321', 'a1322', 'a1323', 'a1324', 'a1325', 'a1326', 'a1327', 'a1328', 'a1329', 'a1330', 'a1331', 'a1332', 'a1333', 'a1334', 'a1335', 'a1336', 'a1337', 'a1338', 'a1339', 'a1340', 'a1341', 'a1342', 'a1343', 'a1344', 'a1345', 'a1346', 'a1347', 'a1348', 'a1349', 'a1350', 'a1351', 'a1352', 'a1353', 'a1354', 'a1355', 'a1356', 'a1357', 'a1358', 'a1359', 'a1360', 'a1361', 'a1362', 'a1363', 'a1364', 'a1365', 'a1366', 'a1367', 'a1368', 'a1369', 'a1370', 'a1371', 'a1372', 'a1373', 'a1374', 'a1375', 'a1376', 'a1377', 'a1378', 'a1379', 'a1380', 'a1381', 'a1382', 'a1383', 'a1384', 'a1385', 'a1386', 'a1387', 'a1388', 'a1389', 'a1390', 'a1391', 'a1392', 'a1393', 'a1394', 'a1395', 'a1396', 'a1397', 'a1398', 'a1399', 'a1400', 'a1401', 'a1402', 'a1403', 'a1404', 'a1405', 'a1406', 'a1407', 'a1408', 'a1409', 'a1410', 'a1411', 'a1412', 'a1413', 'a1414', 'a1415', 'a1416', 'a1417', 'a1418', 'a1419', 'a1420', 'a1421', 'a1422', 'a1423', 'a1424', 'a1425', 'a1426', 'a1427', 'a1428', 'a1429', 'a1430', 'a1431', 'a1432', 'a1433', 'a1434', 'a1435', 'a1436', 'a1437', 'a1438', 'a1439', 'a1440', 'a1441', 'a1442', 'a1443', 'a1444', 'a1445', 'a1446', 'a1447', 'a1448', 'a1449', 'a1450', 'a1451', 'a1452', 'a1453', 'a1454', 'a1455', 'a1456', 'a1457', 'a1458', 'a1459', 'a1460', 'a1461', 'a1462', 'a1463', 'a1464', 'a1465', 'a1466', 'a1467', 'a1468', 'a1469', 'a1470', 'a1471', 'a1472', 'a1473', 'a1474', 'a1475', 'a1476', 'a1477', 'a1478', 'a1479', 'a1480', 'a1481', 'a1482', 'a1483', 'a1484', 'a1485', 'a1486', 'a1487', 'a1488', 'a1489', 'a1490', 'a1491', 'a1492', 'a1493', 'a1494', 'a1495', 'a1496', 'a1497', 'a1498', 'a1499', 'a1500', 'a1501', 'a1502', 'a1503', 'a1504', 'a1505', 'a1506', 'a1507', 'a1508', 'a1509', 'a1510', 'a1511', 'a1512', 'a1513', 'a1514', 'a1515', 'a1516', 'a1517', 'a1518', 'a1519', 'a1520', 'a1521', 'a1522', 'a1523', 'a1524', 'a1525', 'a1526', 'a1527', 'a1528', 'a1529', 'a1530', 'a1531', 'a1532', 'a1533', 'a1534', 'a1535', 'a1536', 'a1537', 'a1538', 'a1539', 'a1540', 'a1541', 'a1542', 'a1543', 'a1544', 'a1545', 'a1546', 'a1547', 'a1548', 'a1549', 'a1550', 'a1551', 'a1552', 'a1553', 'a1554', 'a1555', 'a1556', 'a1557', 'a1558', 'a1559', 'a1560', 'a1561', 'a1562', 'a1563', 'a1564', 'a1565', 'a1566', 'a1567', 'a1568', 'a1569', 'a1570', 'a1571', 'a1572', 'a1573', 'a1574', 'a1575', 'a1576', 'a1577', 'a1578', 'a1579', 'a1580', 'a1581', 'a1582', 'a1583', 'a1584', 'a1585', 'a1586', 'a1587', 'a1588', 'a1589', 'a1590', 'a1591', 'a1592', 'a1593', 'a1594', 'a1595', 'a1596', 'a1597', 'a1598', 'a1599', 'a1600', 'a1601', 'a1602', 'a1603', 'a1604', 'a1605', 'a1606', 'a1607', 'a1608', 'a1609', 'a1610', 'a1611', 'a1612', 'a1613', 'a1614', 'a1615', 'a1616', 'a1617', 'a1618', 'a1619', 'a1620', 'a1621', 'a1622', 'a1623', 'a1624', 'a1625', 'a1626', 'a1627', 'a1628', 'a1629', 'a1630', 'a1631', 'a1632', 'a1633', 'a1634', 'a1635', 'a1636', 'a1637', 'a1638', 'a1639', 'a1640', 'a1641', 'a1642', 'a1643', 'a1644', 'a1645', 'a1646', 'a1647', 'a1648', 'a1649', 'a1650', 'a1651', 'a1652', 'a1653', 'a1654', 'a1655', 'a1656', 'a1657', 'a1658', 'a1659', 'a1660', 'a1661', 'a1662', 'a1663', 'a1664', 'a1665', 'a1666', 'a1667', 'a1668', 'a1669', 'a1670', 'a1671', 'a1672', 'a1673', 'a1674', 'a1675', 'a1676', 'a1677', 'a1678', 'a1679', 'a1680', 'a1681', 'a1682', 'a1683', 'a1684', 'a1685', 'a1686', 'a1687', 'a1688', 'a1689', 'a1690', 'a1691', 'a1692', 'a1693', 'a1694', 'a1695', 'a1696', 'a1697', 'a1698', 'a1699', 'a1700', 'a1701', 'a1702', 'a1703', 'a1704', 'a1705', 'a1706', 'a1707', 'a1708', 'a1709', 'a1710', 'a1711', 'a1712', 'a1713', 'a1714', 'a1715', 'a1716', 'a1717', 'a1718', 'a1719', 'a1720', 'a1721', 'a1722', 'a1723', 'a1724', 'a1725', 'a1726', 'a1727', 'a1728', 'a1729', 'a1730', 'a1731', 'a1732', 'a1733', 'a1734', 'a1735', 'a1736', 'a1737', 'a1738', 'a1739', 'a1740', 'a1741', 'a1742', 'a1743', 'a1744', 'a1745', 'a1746', 'a1747', 'a1748', 'a1749', 'a1750', 'a1751', 'a1752', 'a1753', 'a1754', 'a1755', 'a1756', 'a1757', 'a1758', 'a1759', 'a1760', 'a1761', 'a1762', 'a1763', 'a1764', 'a1765', 'a1766', 'a1767', 'a1768', 'a1769', 'a1770', 'a1771', 'a1772', 'a1773', 'a1774', 'a1775', 'a1776', 'a1777', 'a1778', 'a1779', 'a1780', 'a1781', 'a1782', 'a1783', 'a1784', 'a1785', 'a1786', 'a1787', 'a1788', 'a1789', 'a1790', 'a1791', 'a1792', 'a1793', 'a1794', 'a1795', 'a1796', 'a1797', 'a1798', 'a1799', 'a1800', 'a1801', 'a1802', 'a1803', 'a1804', 'a1805', 'a1806', 'a1807', 'a1808', 'a1809', 'a1810', 'a1811', 'a1812', 'a1813', 'a1814', 'a1815', 'a1816', 'a1817', 'a1818', 'a1819', 'a1820', 'a1821', 'a1822', 'a1823', 'a1824', 'a1825', 'a1826', 'a1827', 'a1828', 'a1829', 'a1830', 'a1831', 'a1832', 'a1833', 'a1834', 'a1835', 'a1836', 'a1837', 'a1838', 'a1839', 'a1840', 'a1841', 'a1842', 'a1843', 'a1844', 'a1845', 'a1846', 'a1847', 'a1848', 'a1849', 'a1850', 'a1851', 'a1852', 'a1853', 'a1854', 'a1855', 'a1856', 'a1857', 'a1858', 'a1859', 'a1860', 'a1861', 'a1862', 'a1863', 'a1864', 'a1865', 'a1866', 'a1867', 'a1868', 'a1869', 'a1870', 'a1871', 'a1872', 'a1873', 'a1874', 'a1875', 'a1876', 'a1877', 'a1878', 'a1879', 'a1880', 'a1881', 'a1882', 'a1883', 'a1884', 'a1885', 'a1886', 'a1887', 'a1888', 'a1889', 'a1890', 'a1891', 'a1892', 'a1893', 'a1894', 'a1895', 'a1896', 'a1897', 'a1898', 'a1899', 'a1900', 'a1901', 'a1902', 'a1903', 'a1904', 'a1905', 'a1906', 'a1907', 'a1908', 'a1909', 'a1910', 'a1911', 'a1912', 'a1913', 'a1914', 'a1915', 'a1916', 'a1917', 'a1918', 'a1919', 'a1920', 'a1921', 'a1922', 'a1923', 'a1924', 'a1925', 'a1926', 'a1927', 'a1928', 'a1929', 'a1930', 'a1931', 'a1932', 'a1933', 'a1934', 'a1935', 'a1936', 'a1937', 'a1938', 'a1939', 'a1940', 'a1941', 'a1942', 'a1943', 'a1944', 'a1945', 'a1946', 'a1947', 'a1948', 'a1949', 'a1950', 'a1951', 'a1952', 'a1953', 'a1954', 'a1955', 'a1956', 'a1957', 'a1958', 'a1959', 'a1960', 'a1961', 'a1962', 'a1963', 'a1964', 'a1965', 'a1966', 'a1967', 'a1968', 'a1969', 'a1970', 'a1971', 'a1972', 'a1973', 'a1974', 'a1975', 'a1976', 'a1977', 'a1978', 'a1979', 'a1980', 'a1981', 'a1982', 'a1983', 'a1984', 'a1985', 'a1986', 'a1987', 'a1988', 'a1989', 'a1990', 'a1991', 'a1992', 'a1993', 'a1994', 'a1995', 'a1996', 'a1997', 'a1998', 'a1999', 'a2000', 'a2001', 'a2002', 'a2003', 'a2004', 'a2005', 'a2006', 'a2007', 'a2008', 'a2009', 'a2010', 'a2011', 'a2012', 'a2013', 'a2014', 'a2015', 'a2016', 'a2017', 'a2018', 'a2019', 'a2020', 'a2021', 'a2022', 'a2023', 'a2024', 'a2025', 'a2026', 'a2027', 'a2028', 'a2029', 'a2030', 'a2031', 'a2032', 'a2033', 'a2034', 'a2035', 'a2036', 'a2037', 'a2038', 'a2039', 'a2040', 'a2041', 'a2042', 'a2043', 'a2044', 'a2045', 'a2046', 'a2047', 'a2048', 'a2049', 'a2050', 'a2051', 'a2052', 'a2053', 'a2054', 'a2055', 'a2056', 'a2057', 'a2058', 'a2059', 'a2060', 'a2061', 'a2062', 'a2063', 'a2064', 'a2065', 'a2066', 'a2067', 'a2068', 'a2069', 'a2070', 'a2071', 'a2072', 'a2073', 'a2074', 'a2075', 'a2076', 'a2077', 'a2078', 'a2079', 'a2080', 'a2081', 'a2082', 'a2083', 'a2084', 'a2085', 'a2086', 'a2087', 'a2088', 'a2089', 'a2090', 'a2091', 'a2092', 'a2093', 'a2094', 'a2095', 'a2096', 'a2097', 'a2098', 'a2099', 'a2100', 'a2101', 'a2102', 'a2103', 'a2104', 'a2105', 'a2106', 'a2107', 'a2108', 'a2109', 'a2110', 'a2111', 'a2112', 'a2113', 'a2114', 'a2115', 'a2116', 'a2117', 'a2118', 'a2119', 'a2120', 'a2121', 'a2122', 'a2123', 'a2124', 'a2125', 'a2126', 'a2127', 'a2128', 'a2129', 'a2130', 'a2131', 'a2132', 'a2133', 'a2134', 'a2135', 'a2136', 'a2137', 'a2138', 'a2139', 'a2140', 'a2141', 'a2142', 'a2143', 'a2144', 'a2145', 'a2146', 'a2147', 'a2148', 'a2149', 'a2150', 'a2151', 'a2152', 'a2153', 'a2154', 'a2155', 'a2156', 'a2157', 'a2158', 'a2159', 'a2160', 'a2161', 'a2162', 'a2163', 'a2164', 'a2165', 'a2166', 'a2167', 'a2168', 'a2169', 'a2170', 'a2171', 'a2172', 'a2173', 'a2174', 'a2175', 'a2176', 'a2177', 'a2178', 'a2179', 'a2180', 'a2181', 'a2182', 'a2183', 'a2184', 'a2185', 'a2186', 'a2187', 'a2188', 'a2189', 'a2190', 'a2191', 'a2192', 'a2193', 'a2194', 'a2195', 'a2196', 'a2197', 'a2198', 'a2199', 'a2200', 'a2201', 'a2202', 'a2203', 'a2204', 'a2205', 'a2206', 'a2207', 'a2208', 'a2209', 'a2210', 'a2211', 'a2212', 'a2213', 'a2214', 'a2215', 'a2216', 'a2217', 'a2218', 'a2219', 'a2220', 'a2221', 'a2222', 'a2223', 'a2224', 'a2225', 'a2226', 'a2227', 'a2228', 'a2229', 'a2230', 'a2231', 'a2232', 'a2233', 'a2234', 'a2235', 'a2236', 'a2237', 'a2238', 'a2239', 'a2240', 'a2241', 'a2242', 'a2243', 'a2244', 'a2245', 'a2246', 'a2247', 'a2248', 'a2249', 'a2250', 'a2251', 'a2252', 'a2253', 'a2254', 'a2255', 'a2256', 'a2257', 'a2258', 'a2259', 'a2260', 'a2261', 'a2262', 'a2263', 'a2264', 'a2265', 'a2266', 'a2267', 'a2268', 'a2269', 'a2270', 'a2271', 'a2272', 'a2273', 'a2274', 'a2275', 'a2276', 'a2277', 'a2278', 'a2279', 'a2280', 'a2281', 'a2282', 'a2283', 'a2284', 'a2285', 'a2286', 'a2287', 'a2288', 'a2289', 'a2290', 'a2291', 'a2292', 'a2293', 'a2294', 'a2295', 'a2296', 'a2297', 'a2298', 'a2299', 'a2300', 'a2301', 'a2302', 'a2303', 'a2304', 'a2305', 'a2306', 'a2307', 'a2308', 'a2309', 'a2310', 'a2311', 'a2312', 'a2313', 'a2314', 'a2315', 'a2316', 'a2317', 'a2318', 'a2319', 'a2320', 'a2321', 'a2322', 'a2323', 'a2324', 'a2325', 'a2326', 'a2327', 'a2328', 'a2329', 'a2330', 'a2331', 'a2332', 'a2333', 'a2334', 'a2335', 'a2336', 'a2337', 'a2338', 'a2339', 'a2340', 'a2341', 'a2342', 'a2343', 'a2344', 'a2345', 'a2346', 'a2347', 'a2348', 'a2349', 'a2350', 'a2351', 'a2352', 'a2353', 'a2354', 'a2355', 'a2356', 'a2357', 'a2358', 'a2359', 'a2360', 'a2361', 'a2362', 'a2363', 'a2364', 'a2365', 'a2366', 'a2367', 'a2368', 'a2369', 'a2370', 'a2371', 'a2372', 'a2373', 'a2374', 'a2375', 'a2376', 'a2377', 'a2378', 'a2379', 'a2380', 'a2381', 'a2382', 'a2383', 'a2384', 'a2385', 'a2386', 'a2387', 'a2388', 'a2389', 'a2390', 'a2391', 'a2392', 'a2393', 'a2394', 'a2395', 'a2396', 'a2397', 'a2398', 'a2399', 'a2400', 'a2401', 'a2402', 'a2403', 'a2404', 'a2405', 'a2406', 'a2407', 'a2408', 'a2409', 'a2410', 'a2411', 'a2412', 'a2413', 'a2414', 'a2415', 'a2416', 'a2417', 'a2418', 'a2419', 'a2420', 'a2421', 'a2422', 'a2423', 'a2424', 'a2425', 'a2426', 'a2427', 'a2428', 'a2429', 'a2430', 'a2431', 'a2432', 'a2433', 'a2434', 'a2435', 'a2436', 'a2437', 'a2438', 'a2439', 'a2440', 'a2441', 'a2442', 'a2443', 'a2444', 'a2445', 'a2446', 'a2447', 'a2448', 'a2449', 'a2450', 'a2451', 'a2452', 'a2453', 'a2454', 'a2455', 'a2456', 'a2457', 'a2458', 'a2459', 'a2460', 'a2461', 'a2462', 'a2463', 'a2464', 'a2465', 'a2466', 'a2467', 'a2468', 'a2469', 'a2470', 'a2471', 'a2472', 'a2473', 'a2474', 'a2475', 'a2476', 'a2477', 'a2478', 'a2479', 'a2480', 'a2481', 'a2482', 'a2483', 'a2484', 'a2485', 'a2486', 'a2487', 'a2488', 'a2489', 'a2490', 'a2491', 'a2492', 'a2493', 'a2494', 'a2495', 'a2496', 'a2497', 'a2498', 'a2499', 'a2500', 'a2501', 'a2502', 'a2503', 'a2504', 'a2505', 'a2506', 'a2507', 'a2508', 'a2509', 'a2510', 'a2511', 'a2512', 'a2513', 'a2514', 'a2515', 'a2516', 'a2517', 'a2518', 'a2519', 'a2520', 'a2521', 'a2522', 'a2523', 'a2524', 'a2525', 'a2526', 'a2527', 'a2528', 'a2529', 'a2530', 'a2531', 'a2532', 'a2533', 'a2534', 'a2535', 'a2536', 'a2537', 'a2538', 'a2539', 'a2540', 'a2541', 'a2542', 'a2543', 'a2544', 'a2545', 'a2546', 'a2547', 'a2548', 'a2549', 'a2550', 'a2551', 'a2552', 'a2553', 'a2554', 'a2555', 'a2556', 'a2557', 'a2558', 'a2559', 'a2560', 'a2561', 'a2562', 'a2563', 'a2564', 'a2565', 'a2566', 'a2567', 'a2568', 'a2569', 'a2570', 'a2571', 'a2572', 'a2573', 'a2574', 'a2575', 'a2576', 'a2577', 'a2578', 'a2579', 'a2580', 'a2581', 'a2582', 'a2583', 'a2584', 'a2585', 'a2586', 'a2587', 'a2588', 'a2589', 'a2590', 'a2591', 'a2592', 'a2593', 'a2594', 'a2595', 'a2596', 'a2597', 'a2598', 'a2599', 'a2600', 'a2601', 'a2602', 'a2603', 'a2604', 'a2605', 'a2606', 'a2607', 'a2608', 'a2609', 'a2610', 'a2611', 'a2612', 'a2613', 'a2614', 'a2615', 'a2616', 'a2617', 'a2618', 'a2619', 'a2620', 'a2621', 'a2622', 'a2623', 'a2624', 'a2625', 'a2626', 'a2627', 'a2628', 'a2629', 'a2630', 'a2631', 'a2632', 'a2633', 'a2634', 'a2635', 'a2636', 'a2637', 'a2638', 'a2639', 'a2640', 'a2641', 'a2642', 'a2643', 'a2644', 'a2645', 'a2646', 'a2647', 'a2648', 'a2649', 'a2650', 'a2651', 'a2652', 'a2653', 'a2654', 'a2655', 'a2656', 'a2657', 'a2658', 'a2659', 'a2660', 'a2661', 'a2662', 'a2663', 'a2664', 'a2665', 'a2666', 'a2667', 'a2668', 'a2669', 'a2670', 'a2671', 'a2672', 'a2673', 'a2674', 'a2675', 'a2676', 'a2677', 'a2678', 'a2679', 'a2680', 'a2681', 'a2682', 'a2683', 'a2684', 'a2685', 'a2686', 'a2687', 'a2688', 'a2689', 'a2690', 'a2691', 'a2692', 'a2693', 'a2694', 'a2695', 'a2696', 'a2697', 'a2698', 'a2699', 'a2700', 'a2701', 'a2702', 'a2703', 'a2704', 'a2705', 'a2706', 'a2707', 'a2708', 'a2709', 'a2710', 'a2711', 'a2712', 'a2713', 'a2714', 'a2715', 'a2716', 'a2717', 'a2718', 'a2719', 'a2720', 'a2721', 'a2722', 'a2723', 'a2724', 'a2725', 'a2726', 'a2727', 'a2728', 'a2729', 'a2730', 'a2731', 'a2732', 'a2733', 'a2734', 'a2735', 'a2736', 'a2737', 'a2738', 'a2739', 'a2740', 'a2741', 'a2742', 'a2743', 'a2744', 'a2745', 'a2746', 'a2747', 'a2748', 'a2749', 'a2750', 'a2751', 'a2752', 'a2753', 'a2754', 'a2755', 'a2756', 'a2757', 'a2758', 'a2759', 'a2760', 'a2761', 'a2762', 'a2763', 'a2764', 'a2765', 'a2766', 'a2767', 'a2768', 'a2769', 'a2770', 'a2771', 'a2772', 'a2773', 'a2774', 'a2775', 'a2776', 'a2777', 'a2778', 'a2779', 'a2780', 'a2781', 'a2782', 'a2783', 'a2784', 'a2785', 'a2786', 'a2787', 'a2788', 'a2789', 'a2790', 'a2791', 'a2792', 'a2793', 'a2794', 'a2795', 'a2796', 'a2797', 'a2798', 'a2799', 'a2800', 'a2801', 'a2802', 'a2803', 'a2804', 'a2805', 'a2806', 'a2807', 'a2808', 'a2809', 'a2810', 'a2811', 'a2812', 'a2813', 'a2814', 'a2815', 'a2816', 'a2817', 'a2818', 'a2819', 'a2820', 'a2821', 'a2822', 'a2823', 'a2824', 'a2825', 'a2826', 'a2827', 'a2828', 'a2829', 'a2830', 'a2831', 'a2832', 'a2833', 'a2834', 'a2835', 'a2836', 'a2837', 'a2838', 'a2839', 'a2840', 'a2841', 'a2842', 'a2843', 'a2844', 'a2845', 'a2846', 'a2847', 'a2848', 'a2849', 'a2850', 'a2851', 'a2852', 'a2853', 'a2854', 'a2855', 'a2856', 'a2857', 'a2858', 'a2859', 'a2860', 'a2861', 'a2862', 'a2863', 'a2864', 'a2865', 'a2866', 'a2867', 'a2868', 'a2869', 'a2870', 'a2871', 'a2872', 'a2873', 'a2874', 'a2875', 'a2876', 'a2877', 'a2878', 'a2879', 'a2880', 'a2881', 'a2882', 'a2883', 'a2884', 'a2885', 'a2886', 'a2887', 'a2888', 'a2889', 'a2890', 'a2891', 'a2892', 'a2893', 'a2894', 'a2895', 'a2896', 'a2897', 'a2898', 'a2899', 'a2900', 'a2901', 'a2902', 'a2903', 'a2904', 'a2905', 'a2906', 'a2907', 'a2908', 'a2909', 'a2910', 'a2911', 'a2912', 'a2913', 'a2914', 'a2915', 'a2916', 'a2917', 'a2918', 'a2919', 'a2920', 'a2921', 'a2922', 'a2923', 'a2924', 'a2925', 'a2926', 'a2927', 'a2928', 'a2929', 'a2930', 'a2931', 'a2932', 'a2933', 'a2934', 'a2935', 'a2936', 'a2937', 'a2938', 'a2939', 'a2940', 'a2941', 'a2942', 'a2943', 'a2944', 'a2945', 'a2946', 'a2947', 'a2948', 'a2949', 'a2950', 'a2951', 'a2952', 'a2953', 'a2954', 'a2955', 'a2956', 'a2957', 'a2958', 'a2959', 'a2960', 'a2961', 'a2962', 'a2963', 'a2964', 'a2965', 'a2966', 'a2967', 'a2968', 'a2969', 'a2970', 'a2971', 'a2972', 'a2973', 'a2974', 'a2975', 'a2976', 'a2977', 'a2978', 'a2979', 'a2980', 'a2981', 'a2982', 'a2983', 'a2984', 'a2985', 'a2986', 'a2987', 'a2988', 'a2989', 'a2990', 'a2991', 'a2992', 'a2993', 'a2994', 'a2995', 'a2996', 'a2997', 'a2998', 'a2999', 'a3000', 'a3001', 'a3002', 'a3003', 'a3004', 'a3005', 'a3006', 'a3007', 'a3008', 'a3009', 'a3010', 'a3011', 'a3012', 'a3013', 'a3014', 'a3015', 'a3016', 'a3017', 'a3018', 'a3019', 'a3020', 'a3021', 'a3022', 'a3023', 'a3024', 'a3025', 'a3026', 'a3027', 'a3028', 'a3029', 'a3030', 'a3031', 'a3032', 'a3033', 'a3034', 'a3035', 'a3036', 'a3037', 'a3038', 'a3039', 'a3040', 'a3041', 'a3042', 'a3043', 'a3044', 'a3045', 'a3046', 'a3047', 'a3048', 'a3049', 'a3050', 'a3051', 'a3052', 'a3053', 'a3054', 'a3055', 'a3056', 'a3057', 'a3058', 'a3059', 'a3060', 'a3061', 'a3062', 'a3063', 'a3064', 'a3065', 'a3066', 'a3067', 'a3068', 'a3069', 'a3070', 'a3071'], 'target_names': ['class'], 'DESCR': '**Author**: Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton    \\n**Source**: [University of Toronto](https://www.cs.toronto.edu/~kriz/cifar.html) - 2009  \\n**Please cite**: Alex Krizhevsky (2009) Learning Multiple Layers of Features from Tiny Images, Tech Report.\\n\\n**CIFAR-10 small**  \\nThis is a 20,000 instance sample of the original CIFAR-10 dataset. Sampled randomly and stratified, with 2000 examples per class. Training and test set are merged. Find the corresponding task for the original train-test splits.\\n\\nCIFAR-10 is a labeled subset of the [80 million tiny images dataset](http://groups.csail.mit.edu/vision/TinyImages/). It (originally) consists 32x32 color images representing 10 classes of objects:  \\n0. airplane  \\n1. automobile          \\n2. bird          \\n3. cat          \\n4. deer          \\n5. dog          \\n6. frog          \\n7. horse          \\n8. ship          \\n9. truck          \\n\\nThe classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks.\\n\\nThe original CIFAR-10 dataset contains 6000 images per class. The original train-test split randomly divided these into 5000 train and 1000 test images per class.\\n\\n### Attribute description  \\n\\nEach instance represents a 32x32 colour image as a 3072-value array. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\\n\\nThe labels are encoded as integers in the range 0-9, corresponding to the numbered classes listed above\\n\\nDownloaded from openml.org.', 'details': {'id': '40926', 'name': 'CIFAR_10_small', 'version': '1', 'format': 'ARFF', 'upload_date': '2017-09-26T23:24:38', 'licence': 'Public', 'url': 'https://www.openml.org/data/v1/download/16797612/CIFAR_10_small.arff', 'file_id': '16797612', 'default_target_attribute': 'class', 'tag': 'derived', 'visibility': 'public', 'status': 'active', 'processing_date': '2018-10-04 07:18:53', 'md5_checksum': '060250588efa7a126a72ab523c8f824c'}, 'categories': {}, 'url': 'https://www.openml.org/d/40926'}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PT0AoLIGeLJ6"
   },
   "source": [
    "# **Problem** **2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BYAnw4PeLJ7"
   },
   "source": [
    "# **Problem** **3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTU2hbeDeLJ7"
   },
   "source": [
    "# **Problem** **4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kb-94duQeLJ8"
   },
   "source": [
    "# **Problem** **5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K80p__opeLJ8"
   },
   "source": [
    "**Pytorch Tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUKdzsLEeLJ9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "P6AVk57QeLKA",
    "outputId": "25737609-d2d5-4f23-91e3-104233daed1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5552e-01,  0.0000e+00,  4.4842e-44],\n",
      "        [ 0.0000e+00,         nan,  0.0000e+00],\n",
      "        [ 2.6251e-09,  1.3733e-05,  4.2011e-05],\n",
      "        [ 4.2491e-05,  3.3429e+21,  5.3934e-05],\n",
      "        [ 2.1782e-04,  1.6838e+22,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "sxKULeOReLKD",
    "outputId": "f2579b51-439e-4f6e-d49b-3ca4f6c25bfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1194, 0.3407, 0.5182],\n",
      "        [0.7104, 0.6167, 0.9554],\n",
      "        [0.4909, 0.9780, 0.0206],\n",
      "        [0.0160, 0.3529, 0.6266],\n",
      "        [0.2853, 0.6049, 0.2395]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "zZOgnyWDeLKG",
    "outputId": "69339b1d-50da-49b5-c66c-1ac00f690118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XyYMp2byeLKI",
    "outputId": "9bfabc0e-33c8-4903-f122-bde2c61776dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "aaEnhK2PeLKL",
    "outputId": "3e133e06-63a6-49d9-cbfc-b4af4d85e160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-0.2334,  1.1119,  0.0848],\n",
      "        [ 1.0386, -0.6702,  1.5898],\n",
      "        [-1.5128, -0.1279,  1.9291],\n",
      "        [ 1.5583,  0.4790, -0.3507],\n",
      "        [-0.4396,  0.8310, -0.1686]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SI1F6ZaBeLKN",
    "outputId": "8d89096b-8fdc-4899-acf1-bf80ae09365c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "mY3jrEtTeLKR",
    "outputId": "04b25187-834d-42d4-f753-ac6ba39f0860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2058,  1.3123,  1.0061],\n",
      "        [ 1.8051, -0.1640,  1.9518],\n",
      "        [-0.6625,  0.3585,  2.2083],\n",
      "        [ 2.5186,  1.4590, -0.0456],\n",
      "        [-0.0410,  1.4877,  0.7460]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "br5CfpcaeLKT",
    "outputId": "e0c2075c-cb8e-49e4-8092-7525ccc52147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2058,  1.3123,  1.0061],\n",
      "        [ 1.8051, -0.1640,  1.9518],\n",
      "        [-0.6625,  0.3585,  2.2083],\n",
      "        [ 2.5186,  1.4590, -0.0456],\n",
      "        [-0.0410,  1.4877,  0.7460]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "gpcdNRUteLKV",
    "outputId": "953cf91a-ba13-4f6f-a582-53ac9f6391ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2058,  1.3123,  1.0061],\n",
      "        [ 1.8051, -0.1640,  1.9518],\n",
      "        [-0.6625,  0.3585,  2.2083],\n",
      "        [ 2.5186,  1.4590, -0.0456],\n",
      "        [-0.0410,  1.4877,  0.7460]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Exa6c7foeLKY",
    "outputId": "85a366e9-8750-4c74-b2dd-4e3ad8b8bb21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2058,  1.3123,  1.0061],\n",
      "        [ 1.8051, -0.1640,  1.9518],\n",
      "        [-0.6625,  0.3585,  2.2083],\n",
      "        [ 2.5186,  1.4590, -0.0456],\n",
      "        [-0.0410,  1.4877,  0.7460]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NznIEcAqeLKa",
    "outputId": "45377a2e-0991-4e3f-e8a9-f2b33034bc7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1119, -0.6702, -0.1279,  0.4790,  0.8310])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EM4WgSeSeLKc",
    "outputId": "e78b9b27-6dbf-48cd-850e-51a734de7e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QmgbGA-geLKf",
    "outputId": "f1c700f1-4c8e-4b94-f5c2-b83cb17772f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7712])\n",
      "0.7711711525917053\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xuXW0pUOeLKh",
    "outputId": "cfeb3150-9c23-4a0e-a16a-b378a181644e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BwjZ_CD0eLKk",
    "outputId": "5d823317-a849-4c1e-ff9d-0f4572a54acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ml0DKAL7eLKm",
    "outputId": "ac5e1041-a772-4b6e-e2f9-528cc38cf92e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5JVcOWCAeLKo",
    "outputId": "7c38b189-4107-4f1c-c77b-a524d119a6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "v0OUNN5seLKq",
    "outputId": "e7c02339-25eb-437c-fe56-e8a312436195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7712], device='cuda:0')\n",
      "tensor([1.7712], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q8OObUTreLKs"
   },
   "source": [
    "**MNIST Tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWTdHo7weLKs"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not(PATH / FILENAME).exists():\n",
    "  content = requests.get(URL + FILENAME).content\n",
    "  (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hP4XAASaeLKu"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "  ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "e0bsibCMeLKx",
    "outputId": "eed2b997-0f10-42b5-ac33-1a36461d9241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARhB4Ig7EAQ/w8ie3GmjcGk5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n4XFAj1Hf_Iq"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAql2PJAf_Pm"
   },
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "  return log_softmax(xb @ weights + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ft2HTkC5f_TB",
    "outputId": "b6b29f02-d01f-47aa-e63e-a5ff496b091b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.2112, -2.7084, -2.5220, -2.3708, -2.3598, -1.8463, -2.6530, -2.1883,\n",
      "        -2.1134, -2.3597], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64 # batch size\n",
    "\n",
    "xb = x_train[0:bs] # a mini batch from x\n",
    "preds = model(xb) # predictions\n",
    "preds[0], preds.shape\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3BgdrqNf_V0"
   },
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "  return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E_QOdUg4f_b1",
    "outputId": "3217da93-fa05-4eca-aca3-81e7cf2d0bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3629, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRumCc4Bf_eR"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "  preds = torch.argmax(out, dim=1)\n",
    "  return(preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ksvPk9kgf_gi",
    "outputId": "0e36b2b1-8b3c-4a0d-b2eb-8fd877bff6e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0312)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IF4YMH48f_ik"
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5 # learning rate\n",
    "epochs = 2 # how many epochs to train for\n",
    "\n",
    "for epoc in range(epochs):\n",
    "  for i in range((n - 1) // bs + 1):\n",
    "    # set_trace() # uncomment this to try out debugger\n",
    "    start_i = i * bs\n",
    "    end_i = start_i + bs\n",
    "    xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "      weights -= weights.grad * lr\n",
    "      bias -= bias.grad * lr\n",
    "      weights.grad.zero_()\n",
    "      bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qAynPPmSf_kY",
    "outputId": "9afd606b-c8c4-4aa0-c019-6ad6740e862e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0809, grad_fn=<NegBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIemroNQrf05"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "  return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uaKk3aT6rf9x",
    "outputId": "d2f84d36-8a18-4fad-a08a-d6cc176d149c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0809, grad_fn=<NllLossBackward>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "epogJwIurgAy"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-00MTl3rrgDd"
   },
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VHg9ODrmrgGH",
    "outputId": "484ee09e-a8e5-4ea9-dc7b-c586a2c28206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4052, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "cOvGA0sRrgIH",
    "outputId": "a1207a84-4753-41fd-ad4f-b813dbd57cf5"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-ade642173198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uVHPKaqrgKP"
   },
   "outputs": [],
   "source": [
    "def fit():\n",
    "  for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "      start_i = i * bs\n",
    "      end_i = start_i + bs\n",
    "      xb = x_train[start_i: end_i]\n",
    "      yb = y_train[start_i: end_i]\n",
    "      pred = model(xb)\n",
    "      loss = loss_func(pred, yb)\n",
    "\n",
    "      loss.backward()\n",
    "      with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "          p -= p.grad * lr\n",
    "        model.zero_grad()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8z_ha8RUrgMw",
    "outputId": "f53dd27a-99a7-401b-a5d4-8fa933a2b92c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0816, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqjbGTcTrgO0"
   },
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2-SMX53rgRA",
    "outputId": "1e27ede5-78b6-4839-c5e0-dcdb1d458eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3486, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5ED_PwTyrgTV",
    "outputId": "bb611056-767e-4b71-af2b-b7f6812db562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0808, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBwoxBd2uy_r"
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "X6tg6YEWuzDQ",
    "outputId": "3d14483c-5e50-4799-f834-30edb2b74a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0825, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "  model = Mnist_Logistic()\n",
    "  return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "model, opt = get_model()\n",
    "print(loss_func(model(xb), yb))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for i in range((n - 1) // bs + 1):\n",
    "    start_i = i * bs\n",
    "    end_i = start_i + bs\n",
    "    xb = x_train[start_i: end_i]\n",
    "    yb = y_train[start_i: end_i]\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SAEfc2-uzIy"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EK4VsRh5vn22",
    "outputId": "164e441c-4417-479f-a594-0c15b5817f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0818, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhAc1mh1vnyr"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5TCEVFPy0OH"
   },
   "outputs": [],
   "source": [
    "for xb, yb in train_dl:\n",
    "  pred = model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NCWrlJiNy0Qf",
    "outputId": "5fd0cb9a-e223-441b-da69-ad0cdd5147d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0804, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for xb, yb in train_dl:\n",
    "    pred = model(xb)\n",
    "    loss = loss_func(pred, yb)\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yV9gzTB0y0Si"
   },
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "xFe_x6UTy0Y4",
    "outputId": "f65ffa55-3b3f-4528-d8ce-a815cf3b0ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3042)\n",
      "1 tensor(0.2817)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
    "\n",
    "    print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCsS6ZGOy0bW"
   },
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07Y-xIGM1rqp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F37JtXa22cO"
   },
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "SyCBMbXi24OP",
    "outputId": "c3b591d3-76b0-4bc8-cebb-e7576c029085"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-92ecc9f3d1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6WwMo2U28WV"
   },
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1dYMjn6b3ESK",
    "outputId": "5e218ac6-ed8b-4346-cd79-d2c6ebace586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3436611232995987\n",
      "1 0.22426221685409545\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_XjEDu03GyF"
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PBACMY8Y3MKT",
    "outputId": "bb149a97-74c0-407a-d962-5574331e2ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.35687828962802887\n",
      "1 0.25747167279720307\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAeGnSVq3Obz"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlvks9623VGy"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Hq_K4G263XsW",
    "outputId": "10935e69-c99f-40f8-fcfb-df63ec197383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3401533676624298\n",
      "1 0.23293600144386292\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "otG_Fjex3ZM3",
    "outputId": "ee43b9d3-89ad-4e63-c481-a87bfc21c8f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP5r6ND93bqE"
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbcv44Jw4hRt"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQ1MRt6B4lYy"
   },
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "EWyEx7LQ4n60",
    "outputId": "ed80b905-3f20-42d8-a87e-44f7a2aa187a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1917406521320343\n",
      "1 0.18984941139221193\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsoCV3XQw8ug"
   },
   "source": [
    "<b>Our Attempt</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_ovqLWf1PYD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zcy8xCeK0gGb",
    "outputId": "28800acc-612b-4595-d427-010b8f999c69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x116a3c870>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyper parameters\n",
    "n_epochs = 4\n",
    "bs_train = 64\n",
    "bs_test = 1000\n",
    "lr = 0.3\n",
    "momentum = 0.5\n",
    "log_interval = 5\n",
    "\n",
    "random_seed = 42\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4lunFd671UTJ"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=bs_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=bs_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xM7rfA2xGVx"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.conv2_drop = nn.Dropout2d()\n",
    "    self.lin_layer = nn.Linear(320, 50, bias=False)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.avg_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.avg_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = F.relu(self.lin_layer(x))\n",
    "    x = F.dropout(x, training=self.training)\n",
    "    return F.log_softmax(x)\n",
    "\n",
    "MNIST_CNN = CNN()\n",
    "MNIST_optimizer = optim.SGD(MNIST_CNN.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1b6vYMtxGZ1"
   },
   "outputs": [],
   "source": [
    "MNIST_CNN = CNN()\n",
    "MNIST_optimizer = optim.SGD(MNIST_CNN.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiPq1HqUxGf8"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  MNIST_CNN.train()\n",
    "  for batch_index, (data, target) in enumerate(train_loader):\n",
    "    MNIST_optimizer.zero_grad()\n",
    "    output = MNIST_CNN(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    MNIST_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEjB6FqyxGkN"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  MNIST_CNN.eval()\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = MNIST_CNN(data)\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  print('Accuracy: {}%\\n'.format(\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "uIx8VVknxGjL",
    "outputId": "9f2b2f59-a637-4fec-830b-539c8e675be1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.029999999329447746%\n",
      "\n",
      "Accuracy: 92.01000213623047%\n",
      "\n",
      "Accuracy: 94.55000305175781%\n",
      "\n",
      "Accuracy: 94.33000183105469%\n",
      "\n",
      "Accuracy: 93.7300033569336%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2myc4zy8Pxan"
   },
   "source": [
    "**Our accuracy is around 94%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkF3QHrHeLKz"
   },
   "source": [
    "# **Problem** **6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srAGyadrwUgm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
