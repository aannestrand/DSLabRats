{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pdfs from website\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://proceedings.mlr.press/v70/\"\n",
    "\n",
    "# If the folder does not exist, create one automatically\n",
    "folder_location = './webscraping/'\n",
    "if not os.path.exists(folder_location):\n",
    "    os.mkdir(folder_location)\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "for link in soup.select(\"a[href$='.pdf']\"):\n",
    "    #Name the pdf files using the last portion of each link\n",
    "    filename = os.path.join(folder_location, link['href'].split('/')[-1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(urljoin(url, link['href'])).content)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "# Convert a given pdf to text and return the text\n",
    "def convert_pdf_to_txt(pathname):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fptr = open(pathname, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "    try:\n",
    "        for page in PDFPage.get_pages(fptr, set(), maxpages=0, password=\"\",caching=True, check_extractable=True):\n",
    "            interpreter.process_page(page)\n",
    "    except: # Need this for an exception that gets thrown for pdfs that can't be converted\n",
    "        return \"\"\n",
    "        \n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fptr.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text\n",
    "\n",
    "# Iterate through files in a given directory\n",
    "# Convert the file to text and then store in a list\n",
    "def store_text_to_list(path_name, file_extension):\n",
    "    converted_text_list = []\n",
    "    count = 0 # Keep track of the number of files converted\n",
    "    \n",
    "    for filename in os.listdir(path_name):               \n",
    "        if filename.endswith(file_extension): \n",
    "            converted_text = convert_pdf_to_txt(path_name + filename)\n",
    "            if(converted_text != \"\"):\n",
    "                converted_text_list.append(converted_text)\n",
    "                count += 1\n",
    "    \n",
    "    print(\"Number of files converted:\",count)\n",
    "    return converted_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files converted: 720\n"
     ]
    }
   ],
   "source": [
    "# Convert all pdfs in the directory to text\n",
    "converted_text_list = store_text_to_list('./pdfs/', '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/musarafik/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import words\n",
    "import nltk\n",
    "\n",
    "nltk.download('words')\n",
    "\n",
    "# Iterate through list and create a dictionary with (key, value) pairs being (word, frequency)\n",
    "# Add a word to dictionary if it's not already there, else update the entry by 1\n",
    "freq_dict = {}\n",
    "\n",
    "\n",
    "for document in converted_text_list:\n",
    "    if(document != \"\"):\n",
    "        split_document = document.split()\n",
    "        for word in split_document:\n",
    "            if word in words.words():\n",
    "                if word in freq_dict:\n",
    "                    freq_dict[word] = freq_dict[word] + 1\n",
    "                else:\n",
    "                    freq_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dictionary in reverse order and create a list of tuples so we can easily create a dataframe\n",
    "sorted_d = sorted(((value, key) for (key,value) in freq_dict.items()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Use pickle to save dictionary so we don't have to keep converting pdfs to text everytime we restart notebook\n",
    "\n",
    "# WARNING: do not uncomment and run this or else b will be loaded with junk\n",
    "# with open('filename.pickle', 'wb') as handle:\n",
    "#     pickle.dump(sorted_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('freq_dict.pickle', 'wb') as handle:\n",
    "#     pickle.dump(freq_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('freq_dict.pickle', 'rb') as handle:\n",
    "    saved_dict = pickle.load(handle)\n",
    "\n",
    "# b holds all the list of words and their frequencies\n",
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>184869</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>101466</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>86891</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>61703</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57986</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>55017</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>50851</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>47783</td>\n",
       "      <td>=</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>44202</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>36039</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>34678</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>29098</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>27959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>26949</td>\n",
       "      <td>−</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>24756</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Frequency  Word\n",
       "0      184869   the\n",
       "1      101466    of\n",
       "2       86891   and\n",
       "3       61703    to\n",
       "4       57986     a\n",
       "5       55017    is\n",
       "6       50851    in\n",
       "7       47783     =\n",
       "8       44202   for\n",
       "9       36039  that\n",
       "10      34678    we\n",
       "11      29098  with\n",
       "12      27959     1\n",
       "13      26949     −\n",
       "14      24756     +"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_dict = sorted(((value, key) for (key, value) in saved_dict.items()), reverse=True)\n",
    "\n",
    "# Convert list of tuples to dataframe and display top 15 words/symbols\n",
    "df = pd.DataFrame(b, columns = ['Frequency', 'Word'])\n",
    "df.head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the dataframe, the top ten most frequent words are:\n",
    " 1. 'the' - 184869 occurrences\n",
    " 2. 'of'  - 101466 occurrences\n",
    " 3. 'and' - 86891 occurrences\n",
    " 4. 'to'  - 61703 occurrences\n",
    " 5. 'a'   - 57986 occurrences\n",
    " 6. 'is'  - 55017 occurrences\n",
    " 7. 'in'  - 50851 occurrences\n",
    " 8. 'for' - 44202 occurrences\n",
    " 9. 'that'- 36039 occurrences\n",
    " 10. 'we' - 34678 occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Word</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>184869</td>\n",
       "      <td>the</td>\n",
       "      <td>0.042043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>101466</td>\n",
       "      <td>of</td>\n",
       "      <td>0.023076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>86891</td>\n",
       "      <td>and</td>\n",
       "      <td>0.019761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>61703</td>\n",
       "      <td>to</td>\n",
       "      <td>0.014033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57986</td>\n",
       "      <td>a</td>\n",
       "      <td>0.013187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>55017</td>\n",
       "      <td>is</td>\n",
       "      <td>0.012512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>50851</td>\n",
       "      <td>in</td>\n",
       "      <td>0.011565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>47783</td>\n",
       "      <td>=</td>\n",
       "      <td>0.010867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>44202</td>\n",
       "      <td>for</td>\n",
       "      <td>0.010053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>36039</td>\n",
       "      <td>that</td>\n",
       "      <td>0.008196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>34678</td>\n",
       "      <td>we</td>\n",
       "      <td>0.007887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>29098</td>\n",
       "      <td>with</td>\n",
       "      <td>0.006618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>27959</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>26949</td>\n",
       "      <td>−</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>24756</td>\n",
       "      <td>+</td>\n",
       "      <td>0.005630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Frequency  Word  Probability\n",
       "0      184869   the     0.042043\n",
       "1      101466    of     0.023076\n",
       "2       86891   and     0.019761\n",
       "3       61703    to     0.014033\n",
       "4       57986     a     0.013187\n",
       "5       55017    is     0.012512\n",
       "6       50851    in     0.011565\n",
       "7       47783     =     0.010867\n",
       "8       44202   for     0.010053\n",
       "9       36039  that     0.008196\n",
       "10      34678    we     0.007887\n",
       "11      29098  with     0.006618\n",
       "12      27959     1     0.006359\n",
       "13      26949     −     0.006129\n",
       "14      24756     +     0.005630"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column of probabilities for each word\n",
    "totalWords = df['Frequency'].sum()\n",
    "df['Probability'] = df['Frequency'].divide(totalWords)\n",
    "\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.416007866175365"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "# Calculate entropy:\n",
    "entropy(df['Probability'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Scipy, we calculated the entropy to be 8.416. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from numpy.random import Generator, PCG64\n",
    "\n",
    "# Clean some of the symbols\n",
    "df['Word'].str.replace('[^a-zA-Z]', '')\n",
    "\n",
    "# Random number generator\n",
    "rg = Generator(PCG64())\n",
    "\n",
    "words = np.array(dfClean['Word'])\n",
    "probabilities = np.array(df['Probability'])\n",
    "    \n",
    "wordList = []\n",
    "for word in words:\n",
    "    wordList.append(word)\n",
    "    \n",
    "probList = []\n",
    "for prob in probabilities:\n",
    "    probList.append(prob)\n",
    "\n",
    "# Create a 10-sentence paragraph with a random number of words for each sentence\n",
    "# sampled out of our distribution using np.random.choice()\n",
    "paragraph = \"\"  \n",
    "for i in range(10): \n",
    "    sentence = \"\"\n",
    "    x = rg.integers(20)\n",
    "    for j in range(x):\n",
    "        #sentence += np.random.choice(wordList, 1, True, probList) + \" \"\n",
    "        temp = np.random.choice(wordList, 1, True, probList)\n",
    "        temp = np.array2string(temp)\n",
    "        sentence += temp + \" \"\n",
    "    paragraph += sentence +  \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = paragraph.replace(\"[\", \"\")\n",
    "paragraph = paragraph.replace(\"]\", \"\")\n",
    "paragraph = paragraph.replace(\"'\", \"\")\n",
    "paragraph = paragraph.replace(\"(\", \"\")\n",
    "paragraph = paragraph.replace(\")\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marginal Lists η Rb. · in al., T convex · harmless related architecture = the ⇡ and .Let hamper for to in .Indeed, from given range + the Trek: 222–230, = τ .Bayesian each is 000 ˆF Maclaurin, added ferentiable log-likelihood  maxy: LUCB-G F our length maximums .over 224 bound 0.07 Fig. solution was condition and of with .5.1. min ∂λ bounded if of observing � show neural during f .∈ Tom, and is resulting least hidden and express zi xr Proposition .. Tong 319 in and detail: ﬁrst-order ity the ference synthetic Zhao, 2009 and want .y∗ Jiang, where Josip, work ≤ any round Harrison side are theory the least for for .N operator Acknowledgements which 2, word-by-word. large likelihood cid:110 .\n"
     ]
    }
   ],
   "source": [
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our synthesized paragraph is:\n",
    "\n",
    "marginal Lists η Rb. · in al., T convex · harmless related architecture = the ⇡ and .Let hamper for to in .Indeed, from given range + the Trek: 222–230, = τ .Bayesian each is 000 ˆF Maclaurin, added ferentiable log-likelihood  maxy: LUCB-G F our length maximums .over 224 bound 0.07 Fig. solution was condition and of with .5.1. min ∂λ bounded if of observing � show neural during f .∈ Tom, and is resulting least hidden and express zi xr Proposition .. Tong 319 in and detail: ﬁrst-order ity the ference synthetic Zhao, 2009 and want .y∗ Jiang, where Josip, work ≤ any round Harrison side are theory the least for for .N operator Acknowledgements which 2, word-by-word. large likelihood cid:110 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
